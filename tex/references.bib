@article{arcomano_machine_2020,
	title = {A {Machine} {Learning}-{Based} {Global} {Atmospheric} {Forecast} {Model}},
	volume = {47},
	copyright = {©2020. American Geophysical Union. All Rights Reserved.},
	issn = {1944-8007},
	url = {http://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2020GL087776},
	doi = {10.1029/2020GL087776},
	abstract = {The paper investigates the applicability of machine learning (ML) to weather prediction by building a reservoir computing-based, low-resolution, global prediction model. The model is designed to take advantage of the massively parallel architecture of a modern supercomputer. The forecast performance of the model is assessed by comparing it to that of daily climatology, persistence, and a numerical (physics-based) model of identical prognostic state variables and resolution. Hourly resolution 20-day forecasts with the model predict realistic values of the atmospheric state variables at all forecast times for the entire globe. The ML model outperforms both climatology and persistence for the first three forecast days in the midlatitudes, but not in the tropics. Compared to the numerical model, the ML model performs best for the state variables most affected by parameterized processes in the numerical model.},
	language = {en},
	number = {9},
	urldate = {2020-05-14},
	journal = {Geophysical Research Letters},
	author = {Arcomano, Troy and Szunyogh, Istvan and Pathak, Jaideep and Wikner, Alexander and Hunt, Brian R. and Ott, Edward},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2020GL087776},
	pages = {e2020GL087776},
	annote = {e2020GL087776 10.1029/2020GL087776},
	file = {Arcomano_et_al_2020_A_Machine_Learning-Based_Global_Atmospheric_Forecast_Model.pdf:/Users/tsmith/Drive/zotero/Arcomano_et_al_2020_A_Machine_Learning-Based_Global_Atmospheric_Forecast_Model.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/NCLPUTJ8/2020GL087776.html:text/html},
}

@article{dueben_challenges_2018,
	title = {Challenges and design choices for global weather and climate models based on machine learning},
	volume = {11},
	issn = {1991-959X},
	url = {https://gmd.copernicus.org/articles/11/3999/2018/},
	doi = {https://doi.org/10.5194/gmd-11-3999-2018},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} Can models that are based on deep learning and trained on atmospheric data compete with weather and climate models that are based on physical principles and the basic equations of motion? This question has been asked often recently due to the boom in deep-learning techniques. The question is valid given the huge amount of data that are available, the computational efficiency of deep-learning techniques and the limitations of today's weather and climate models in particular with respect to resolution and complexity.{\textless}/p{\textgreater}{\textless}p{\textgreater}In this paper, the question will be discussed in the context of global weather forecasts. A toy model for global weather predictions will be presented and used to identify challenges and fundamental design choices for a forecast system based on neural networks.{\textless}/p{\textgreater}},
	language = {English},
	number = {10},
	urldate = {2021-02-09},
	journal = {Geoscientific Model Development},
	author = {Dueben, Peter D. and Bauer, Peter},
	month = oct,
	year = {2018},
	note = {Publisher: Copernicus GmbH},
	pages = {3999--4009},
	file = {Dueben_Bauer_2018_Challenges_and_design_choices_for_global_weather_and_climate_models_based_on.pdf:/Users/tsmith/Drive/zotero/Dueben_Bauer_2018_Challenges_and_design_choices_for_global_weather_and_climate_models_based_on.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/5TXEBIWF/2018.html:text/html},
}

@article{rasp_weatherbench_2020,
	title = {{WeatherBench}: {A} {Benchmark} {Data} {Set} for {Data}-{Driven} {Weather} {Forecasting}},
	volume = {12},
	copyright = {©2020. The Authors.},
	issn = {1942-2466},
	shorttitle = {{WeatherBench}},
	url = {http://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2020MS002203},
	doi = {https://doi.org/10.1029/2020MS002203},
	abstract = {Data-driven approaches, most prominently deep learning, have become powerful tools for prediction in many domains. A natural question to ask is whether data-driven methods could also be used to predict global weather patterns days in advance. First studies show promise but the lack of a common data set and evaluation metrics make intercomparison between studies difficult. Here we present a benchmark data set for data-driven medium-range weather forecasting (specifically 3–5 days), a topic of high scientific interest for atmospheric and computer scientists alike. We provide data derived from the ERA5 archive that has been processed to facilitate the use in machine learning models. We propose simple and clear evaluation metrics which will enable a direct comparison between different methods. Further, we provide baseline scores from simple linear regression techniques, deep learning models, as well as purely physical forecasting models. The data set is publicly available at https://github.com/pangeo-data/WeatherBench and the companion code is reproducible with tutorials for getting started. We hope that this data set will accelerate research in data-driven weather forecasting.},
	language = {en},
	number = {11},
	urldate = {2020-11-25},
	journal = {Journal of Advances in Modeling Earth Systems},
	author = {Rasp, Stephan and Dueben, Peter D. and Scher, Sebastian and Weyn, Jonathan A. and Mouatadid, Soukayna and Thuerey, Nils},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2020MS002203},
	keywords = {machine learning, artificial intelligence, benchmark, NWP},
	pages = {e2020MS002203},
	annote = {e2020MS002203 10.1029/2020MS002203},
	file = {Rasp_et_al_2020_WeatherBench.pdf:/Users/tsmith/Drive/zotero/Rasp_et_al_2020_WeatherBench.pdf:application/pdf},
}

@article{nadiga_reservoir_2021,
	title = {Reservoir {Computing} as a {Tool} for {Climate} {Predictability} {Studies}},
	volume = {13},
	issn = {1942-2466},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2020MS002290},
	doi = {10.1029/2020MS002290},
	abstract = {Reduced-order dynamical models play a central role in developing our understanding of predictability of climate irrespective of whether we are dealing with the actual climate system or surrogate climate models. In this context, the linear inverse modeling (LIM) approach, by capturing a few essential interactions between dynamical components of the full system, has proven valuable in providing insights into predictability of the full system. We demonstrate that reservoir computing (RC), a form of learning suitable for systems with chaotic dynamics, provides an alternative nonlinear approach that improves on the predictive skill of the LIM approach. We do this in the example setting of predicting sea surface temperature in the North Atlantic in the preindustrial control simulation of a popular earth system model, the Community Earth System Model so that we can compare the performance of the new RC-based approach with the traditional LIM approach both when learning data are plentiful and when such data are more limited. The improved predictive skill of the RC approach over a wide range of conditions—larger number of retained EOF coefficients, extending well into the limited data regime, etc.—suggests that this machine-learning technique may have a use in climate predictability studies. While the possibility of developing a climate emulator—the ability to continue the evolution of the system on the attractor long after failing to be able to track the reference trajectory—is demonstrated in the Lorenz-63 system, it is suggested that further development of the RC approach may permit such uses of the new approach in more realistic predictability studies.},
	language = {en},
	number = {4},
	urldate = {2021-11-17},
	journal = {Journal of Advances in Modeling Earth Systems},
	author = {Nadiga, Balasubramanya T.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2020MS002290},
	keywords = {machine learning, climate, echo state networks, reservoir computing, linear inverse modeling, predictability},
	pages = {e2020MS002290},
	annote = {e2020MS002290 2020MS002290},
	file = {Nadiga_2021_Reservoir_Computing_as_a_Tool_for_Climate_Predictability_Studies.pdf:/Users/tsmith/Drive/zotero/Nadiga_2021_Reservoir_Computing_as_a_Tool_for_Climate_Predictability_Studies.pdf:application/pdf;Nadiga_2021_Reservoir_Computing_as_a_Tool_for_Climate_Predictability_Studies.pdf:/Users/tsmith/Drive/zotero/Nadiga_2021_Reservoir_Computing_as_a_Tool_for_Climate_Predictability_Studies.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/Q7D3QF8X/2020MS002290.html:text/html},
}

@article{agarwal_comparison_2021,
	title = {A {Comparison} of {Data}-{Driven} {Approaches} to {Build} {Low}-{Dimensional} {Ocean} {Models}},
	volume = {13},
	issn = {1942-2466},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1029/2021MS002537},
	doi = {10.1029/2021MS002537},
	abstract = {We present a comprehensive inter-comparison of linear regression (LR), stochastic, and deep-learning approaches for reduced-order statistical emulation of ocean circulation. The reference data set is provided by an idealized, eddy-resolving, double-gyre ocean circulation model. Our goal is to conduct a systematic and comprehensive assessment and comparison of skill, cost, and complexity of statistical models from the three methodological classes. The model based on LR is considered as a baseline. Additionally, we investigate its additive white noise augmentation and a multi-level stochastic approach, deep-learning methods, hybrid frameworks (LR plus deep-learning), and simple stochastic extensions of deep-learning and hybrid methods. The assessment metrics considered are: root mean squared error, anomaly cross-correlation, climatology, variance, frequency map, forecast horizon, and computational cost. We found that the multi-level linear stochastic approach performs the best for both short- and long-timescale forecasts. The deep-learning hybrid models augmented by additive state-dependent white noise came second, while their deterministic counterparts failed to reproduce the characteristic frequencies in climate-range forecasts. Pure deep learning implementations performed worse than LR and its simple white noise augmentation. Skills of LR and its white noise extension were similar on short timescales, but the latter performed better on long timescales, while LR-only outputs decay to zero for long simulations. Overall, our analysis promotes multi-level LR stochastic models with memory effects, and hybrid models with linear dynamical core augmented by additive stochastic terms learned via deep learning, as a more practical, accurate, and cost-effective option for ocean emulation than pure deep-learning solutions.},
	language = {en},
	number = {9},
	urldate = {2021-12-01},
	journal = {Journal of Advances in Modeling Earth Systems},
	author = {Agarwal, Niraj and Kondrashov, D. and Dueben, P. and Ryzhov, E. and Berloff, P.},
	year = {2021},
	note = {\_eprint: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2021MS002537},
	keywords = {machine learning, data-driven modeling, ocean models, reduced order modeling},
	pages = {e2021MS002537},
	annote = {e2021MS002537 2021MS002537},
	file = {Agarwal_et_al_2021_A_Comparison_of_Data-Driven_Approaches_to_Build_Low-Dimensional_Ocean_Models.pdf:/Users/tsmith/Drive/zotero/Agarwal_et_al_2021_A_Comparison_of_Data-Driven_Approaches_to_Build_Low-Dimensional_Ocean_Models.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/HPRD5JXJ/2021MS002537.html:text/html},
}

@article{chen_predicting_2021,
	title = {Predicting {Shallow} {Water} {Dynamics} using {Echo}-{State} {Networks} with {Transfer} {Learning}},
	url = {http://arxiv.org/abs/2112.09182},
	abstract = {In this paper we demonstrate that reservoir computing can be used to learn the dynamics of the shallow-water equations. In particular, while most previous applications of reservoir computing have required training on a particular trajectory to further predict the evolution along that trajectory alone, we show the capability of reservoir computing to predict trajectories of the shallow-water equations with initial conditions not seen in the training process. However, in this setting, we find that the performance of the network deteriorates for initial conditions with ambient conditions (such as total water height and average velocity) that are different from those in the training dataset. To circumvent this deficiency, we introduce a transfer learning approach wherein a small additional training step with the relevant ambient conditions is used to improve the predictions.},
	urldate = {2022-01-11},
	journal = {arXiv:2112.09182 [physics]},
	author = {Chen, Xiaoqian and Nadiga, Balasubramanya T. and Timofeyev, Ilya},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.09182},
	keywords = {Physics - Geophysics, Computer Science - Machine Learning, 86-08, Physics - Data Analysis, Statistics and Probability},
	file = {arXiv.org Snapshot:/Users/tsmith/Zotero/storage/35L3BN69/2112.html:text/html;Chen_et_al_2021_Predicting_Shallow_Water_Dynamics_using_Echo-State_Networks_with_Transfer.pdf:/Users/tsmith/Drive/zotero/Chen_et_al_2021_Predicting_Shallow_Water_Dynamics_using_Echo-State_Networks_with_Transfer.pdf:application/pdf},
}

@article{keisler_forecasting_2022,
	title = {Forecasting {Global} {Weather} with {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2202.07575},
	abstract = {We present a data-driven approach for forecasting global weather using graph neural networks. The system learns to step forward the current 3D atmospheric state by six hours, and multiple steps are chained together to produce skillful forecasts going out several days into the future. The underlying model is trained on reanalysis data from ERA5 or forecast data from GFS. Test performance on metrics such as Z500 (geopotential height) and T850 (temperature) improves upon previous data-driven approaches and is comparable to operational, full-resolution, physical models from GFS and ECMWF, at least when evaluated on 1-degree scales and when using reanalysis initial conditions. We also show results from connecting this data-driven model to live, operational forecasts from GFS.},
	urldate = {2022-02-17},
	journal = {arXiv:2202.07575 [physics]},
	author = {Keisler, Ryan},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.07575},
	keywords = {Physics - Atmospheric and Oceanic Physics, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tsmith/Zotero/storage/TIIZMUZ4/2202.html:text/html;Keisler_2022_Forecasting_Global_Weather_with_Graph_Neural_Networks.pdf:/Users/tsmith/Drive/zotero/Keisler_2022_Forecasting_Global_Weather_with_Graph_Neural_Networks.pdf:application/pdf},
}

@techreport{lin_fourier_2021,
	type = {preprint},
	title = {Fourier {Reservoir} {Computing} for data-driven prediction of multi-scale coupled quasi-geostrophic dynamics},
	url = {http://www.essoar.org/doi/10.1002/essoar.10509867.1},
	language = {en},
	urldate = {2022-03-08},
	institution = {Geophysics},
	author = {Lin, Hsin-Yi and Penny, Stephen G},
	month = dec,
	year = {2021},
	doi = {10.1002/essoar.10509867.1},
	file = {Lin_Penny_2021_Fourier_Reservoir_Computing_for_data-driven_prediction_of_multi-scale_coupled.pdf:/Users/tsmith/Drive/zotero/Lin_Penny_2021_Fourier_Reservoir_Computing_for_data-driven_prediction_of_multi-scale_coupled.pdf:application/pdf},
}

@article{pathak_fourcastnet_2022,
	title = {{FourCastNet}: {A} {Global} {Data}-driven {High}-resolution {Weather} {Model} using {Adaptive} {Fourier} {Neural} {Operators}},
	shorttitle = {{FourCastNet}},
	url = {http://arxiv.org/abs/2202.11214},
	abstract = {FourCastNet, short for Fourier Forecasting Neural Network, is a global data-driven weather forecasting model that provides accurate short to medium-range global predictions at \$0.25{\textasciicircum}\{{\textbackslash}circ\}\$ resolution. FourCastNet accurately forecasts high-resolution, fast-timescale variables such as the surface wind speed, precipitation, and atmospheric water vapor. It has important implications for planning wind energy resources, predicting extreme weather events such as tropical cyclones, extra-tropical cyclones, and atmospheric rivers. FourCastNet matches the forecasting accuracy of the ECMWF Integrated Forecasting System (IFS), a state-of-the-art Numerical Weather Prediction (NWP) model, at short lead times for large-scale variables, while outperforming IFS for variables with complex fine-scale structure, including precipitation. FourCastNet generates a week-long forecast in less than 2 seconds, orders of magnitude faster than IFS. The speed of FourCastNet enables the creation of rapid and inexpensive large-ensemble forecasts with thousands of ensemble-members for improving probabilistic forecasting. We discuss how data-driven deep learning models such as FourCastNet are a valuable addition to the meteorology toolkit to aid and augment NWP models.},
	urldate = {2022-03-24},
	journal = {arXiv:2202.11214 [physics]},
	author = {Pathak, Jaideep and Subramanian, Shashank and Harrington, Peter and Raja, Sanjeev and Chattopadhyay, Ashesh and Mardani, Morteza and Kurth, Thorsten and Hall, David and Li, Zongyi and Azizzadenesheli, Kamyar and Hassanzadeh, Pedram and Kashinath, Karthik and Anandkumar, Animashree},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.11214},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	file = {arXiv.org Snapshot:/Users/tsmith/Zotero/storage/UZLDZG3C/2202.html:text/html;Pathak_et_al_2022_FourCastNet.pdf:/Users/tsmith/Drive/zotero/Pathak_et_al_2022_FourCastNet.pdf:application/pdf},
}

@article{pandey_reservoir_2020,
	title = {Reservoir computing model of two-dimensional turbulent convection},
	volume = {5},
	url = {https://link.aps.org/doi/10.1103/PhysRevFluids.5.113506},
	doi = {10.1103/PhysRevFluids.5.113506},
	abstract = {Reservoir computing is an efficient implementation of a recurrent neural network that can describe the evolution of a dynamical system by supervised machine learning without solving the underlying mathematical equations. In this work, reservoir computing is applied to model the large-scale evolution and the resulting low-order turbulence statistics of a two-dimensional turbulent Rayleigh-Bénard convection flow at a Rayleigh number Ra=107 and a Prandtl number Pr=7 in an extended spatial domain with an aspect ratio of 6. Our data-driven approach, which is based on a long-term direct numerical simulation of the convection flow, comprises a two-step procedure: (1) reduction of the original simulation data by a proper orthogonal decomposition (POD) snapshot analysis and subsequent truncation to the first 150 POD modes which are associated with the largest total energy amplitudes; (2) setup and optimization of a reservoir computing model to describe the dynamical evolution of these 150 degrees of freedom and thus the large-scale evolution of the convection flow. The quality of the prediction of the reservoir computing model is comprehensively tested by a direct comparison of the results of the original direct numerical simulations and the fields that are reconstructed by means of the POD modes. We find a good agreement of the vertical profiles of mean temperature, mean convective heat flux, and root-mean-square temperature fluctuations. In addition, we discuss temperature variance spectra and joint probability density functions of the turbulent vertical velocity component and temperature fluctuation, the latter of which is essential for the turbulent heat transport across the layer. At the core of the model is the reservoir, a very large sparse random network characterized by the spectral radius of the corresponding adjacency matrix and a few further hyperparameters which are varied to investigate the quality of the prediction. Our work demonstrates that the reservoir computing model is capable of modeling the large-scale structure and low-order statistics of turbulent convection, which can open new avenues for modeling mesoscale convection processes in larger circulation models.},
	number = {11},
	urldate = {2022-05-31},
	journal = {Physical Review Fluids},
	author = {Pandey, Sandeep and Schumacher, Jörg},
	month = nov,
	year = {2020},
	note = {Publisher: American Physical Society},
	pages = {113506},
	file = {APS Snapshot:/Users/tsmith/Zotero/storage/6XFCT9XY/PhysRevFluids.5.html:text/html;Pandey_Schumacher_2020_Reservoir_computing_model_of_two-dimensional_turbulent_convection.pdf:/Users/tsmith/Drive/zotero/Pandey_Schumacher_2020_Reservoir_computing_model_of_two-dimensional_turbulent_convection.pdf:application/pdf},
}

@article{doan_short-_2021,
	title = {Short- and long-term predictions of chaotic flows and extreme events: a physics-constrained reservoir computing approach},
	volume = {477},
	shorttitle = {Short- and long-term predictions of chaotic flows and extreme events},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rspa.2021.0135},
	doi = {10.1098/rspa.2021.0135},
	abstract = {We propose a physics-constrained machine learning method—based on reservoir computing—to time-accurately predict extreme events and long-term velocity statistics in a model of chaotic flow. The method leverages the strengths of two different approaches: empirical modelling based on reservoir computing, which learns the chaotic dynamics from data only, and physical modelling based on conservation laws. This enables the reservoir computing framework to output physical predictions when training data are unavailable. We show that the combination of the two approaches is able to accurately reproduce the velocity statistics, and to predict the occurrence and amplitude of extreme events in a model of self-sustaining process in turbulence. In this flow, the extreme events are abrupt transitions from turbulent to quasi-laminar states, which are deterministic phenomena that cannot be traditionally predicted because of chaos. Furthermore, the physics-constrained machine learning method is shown to be robust with respect to noise. This work opens up new possibilities for synergistically enhancing data-driven methods with physical knowledge for the time-accurate prediction of chaotic flows.},
	number = {2253},
	urldate = {2022-05-31},
	journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Doan, N. a. K. and Polifke, W. and Magri, L.},
	month = sep,
	year = {2021},
	note = {Publisher: Royal Society},
	keywords = {machine learning, reservoir computing, chaotic flows, extreme events},
	pages = {20210135},
	file = {Doan_et_al_2021_Short-_and_long-term_predictions_of_chaotic_flows_and_extreme_events.pdf:/Users/tsmith/Drive/zotero/Doan_et_al_2021_Short-_and_long-term_predictions_of_chaotic_flows_and_extreme_events.pdf:application/pdf},
}

@article{moore_linear_2022,
	title = {A linear stochastic emulator of the {California} {Current} system using balanced truncation},
	volume = {174},
	issn = {14635003},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1463500322000610},
	doi = {10.1016/j.ocemod.2022.102023},
	abstract = {A downscaled reanalysis for the California Current system is used to construct a low-dimensional linear stochastic emulator of the 3-dimensional time evolving ocean circulation. The approach used is based on balanced truncation which simultaneously draws on information from the Empirical Orthogonal Functions (EOFs) and stochastic optimals of the ocean state-vector. In this way, balanced truncation faithfully preserves the inherent stability properties of the data, unlike the more traditional approaches based on truncation using EOFs alone. Since balanced truncation is predicated on singular value decomposition, formal error bounds on the accuracy of the reduced-dimension system can be computed. In addition, linear stochastic emulators that target different physical processes can also be constructed, and examples that focus on a region dominated by coastal upwelling are presented. Linear stochastic emulators, such as that developed here, can be exploited to generate very long simulations (or large ensembles) at high resolution that can be used to establish a statistical baseline for important oceanic processes, calculations that would otherwise be very challenging by direct numerical integration. An example is presented.},
	language = {en},
	urldate = {2022-06-21},
	journal = {Ocean Modelling},
	author = {Moore, Andrew M. and Fiechter, Jérôme and Edwards, Christopher A.},
	month = jun,
	year = {2022},
	pages = {102023},
	file = {Moore_et_al_2022_A_linear_stochastic_emulator_of_the_California_Current_system_using_balanced.pdf:/Users/tsmith/Drive/zotero/Moore_et_al_2022_A_linear_stochastic_emulator_of_the_California_Current_system_using_balanced.pdf:application/pdf},
}

@article{dueben_challenges_2022,
	title = {Challenges and {Benchmark} {Datasets} for {Machine} {Learning} in the {Atmospheric} {Sciences}: {Definition}, {Status}, and {Outlook}},
	volume = {1},
	issn = {2769-7525},
	shorttitle = {Challenges and {Benchmark} {Datasets} for {Machine} {Learning} in the {Atmospheric} {Sciences}},
	url = {https://journals.ametsoc.org/view/journals/aies/1/3/AIES-D-21-0002.1.xml},
	doi = {10.1175/AIES-D-21-0002.1},
	abstract = {Abstract Benchmark datasets and benchmark problems have been a key aspect for the success of modern machine learning applications in many scientific domains. Consequently, an active discussion about benchmarks for applications of machine learning has also started in the atmospheric sciences. Such benchmarks allow for the comparison of machine learning tools and approaches in a quantitative way and enable a separation of concerns for domain and machine learning scientists. However, a clear definition of benchmark datasets for weather and climate applications is missing with the result that many domain scientists are confused. In this paper, we equip the domain of atmospheric sciences with a recipe for how to build proper benchmark datasets, a (nonexclusive) list of domain-specific challenges for machine learning is presented, and it is elaborated where and what benchmark datasets will be needed to tackle these challenges. We hope that the creation of benchmark datasets will help the machine learning efforts in atmospheric sciences to be more coherent, and, at the same time, target the efforts of machine learning scientists and experts of high-performance computing to the most imminent challenges in atmospheric sciences. We focus on benchmarks for atmospheric sciences (weather, climate, and air-quality applications). However, many aspects of this paper will also hold for other aspects of the Earth system sciences or are at least transferable. Significance Statement Machine learning is the study of computer algorithms that learn automatically from data. Atmospheric sciences have started to explore sophisticated machine learning techniques and the community is making rapid progress on the uptake of new methods for a large number of application areas. This paper provides a clear definition of so-called benchmark datasets for weather and climate applications that help to share data and machine learning solutions between research groups to reduce time spent in data processing, to generate synergies between groups, and to make tool developments more targeted and comparable. Furthermore, a list of benchmark datasets that will be needed to tackle important challenges for the use of machine learning in atmospheric sciences is provided.},
	language = {EN},
	number = {3},
	urldate = {2022-08-11},
	journal = {Artificial Intelligence for the Earth Systems},
	author = {Dueben, Peter D. and Schultz, Martin G. and Chantry, Matthew and Gagne, David John and Hall, David Matthew and McGovern, Amy},
	month = jul,
	year = {2022},
	note = {Publisher: American Meteorological Society
Section: Artificial Intelligence for the Earth Systems},
	file = {Dueben_et_al_2022_Challenges_and_Benchmark_Datasets_for_Machine_Learning_in_the_Atmospheric.pdf:/Users/tsmith/Drive/zotero/Dueben_et_al_2022_Challenges_and_Benchmark_Datasets_for_Machine_Learning_in_the_Atmospheric.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/M8WL4X3I/AIES-D-21-0002.1.html:text/html},
}

@article{brunton_machine_2020,
	title = {Machine {Learning} for {Fluid} {Mechanics}},
	volume = {52},
	url = {https://doi.org/10.1146/annurev-fluid-010719-060214},
	doi = {10.1146/annurev-fluid-010719-060214},
	abstract = {The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from experiments, field measurements, and large-scale simulations at multiple spatiotemporal scales. Machine learning (ML) offers a wealth of techniques to extract information from data that can be translated into knowledge about the underlying fluid mechanics. Moreover, ML algorithms can augment domain knowledge and automate tasks related to flow control and optimization. This article presents an overview of past history, current developments, and emerging opportunities of ML for fluid mechanics. We outline fundamental ML methodologies and discuss their uses for understanding, modeling, optimizing, and controlling fluid flows. The strengths and limitations of these methods are addressed from the perspective of scientific inquiry that considers data as an inherent part of modeling, experiments, and simulations. ML provides a powerful information-processing framework that can augment, and possibly even transform, current lines of fluid mechanics research and industrial applications.},
	number = {1},
	urldate = {2022-08-12},
	journal = {Annual Review of Fluid Mechanics},
	author = {Brunton, Steven L. and Noack, Bernd R. and Koumoutsakos, Petros},
	year = {2020},
	note = {\_eprint: https://doi.org/10.1146/annurev-fluid-010719-060214},
	keywords = {machine learning, optimization, data-driven modeling, control},
	pages = {477--508},
	file = {Brunton_et_al_2020_Machine_Learning_for_Fluid_Mechanics.pdf:/Users/tsmith/Drive/zotero/Brunton_et_al_2020_Machine_Learning_for_Fluid_Mechanics.pdf:application/pdf},
}

@article{chattopadhyay_deep_2020,
	title = {Deep spatial transformers for autoregressive data-driven forecasting of geophysical turbulence},
	copyright = {GNU Lesser General Public License (LGPL) 2.1},
	url = {https://eartharxiv.org/repository/view/118/},
	abstract = {A deep spatial transformer based encoder-decoder model has been developed to autoregressively predict the time evolution of the upper layers stream function of a two-layered quasi-geostrophic (QG) system without any information about the lower layers stream function. The spatio-temporal complexity of QG flow is comparable to the complexity of 500hPa Geopotential Height (Z500) of fully coupled climate models or even the Z500 which is observed in the atmosphere, based on the instantaneous attractor dimension metric. The ability to predict autoregressively, the turbulent dynamics of QG is the first step towards building data-driven surrogates for more complex climate models. We show that the equivariance preserving properties of modern spatial transformers incorporated within a convolutional encoder-decoder module can predict up to 9 days in a QG system (outperforming a baseline persistence model and a standard convolutional encoder decoder with a custom loss function). The proposed data-driven model remains stable for multiple years thus promising us of a stable and physical data-driven climate model.},
	language = {en},
	urldate = {2022-08-18},
	author = {Chattopadhyay, Ashesh and Mustafa, Mustafa and Hassanzadeh, Pedram and Kashinath, Karthik},
	month = jul,
	year = {2020},
	note = {Publisher: EarthArXiv},
    journal = {EarthArXiv},
	file = {Chattopadhyay_et_al_2020_Deep_spatial_transformers_for_autoregressive_data-driven_forecasting_of.pdf:/Users/tsmith/Drive/zotero/Chattopadhyay_et_al_2020_Deep_spatial_transformers_for_autoregressive_data-driven_forecasting_of.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/7FRV5NT3/118.html:text/html},
}

@misc{kurth_fourcastnet_2022,
	title = {{FourCastNet}: {Accelerating} {Global} {High}-{Resolution} {Weather} {Forecasting} using {Adaptive} {Fourier} {Neural} {Operators}},
	shorttitle = {{FourCastNet}},
	url = {http://arxiv.org/abs/2208.05419},
	abstract = {Extreme weather amplified by climate change is causing increasingly devastating impacts across the globe. The current use of physics-based numerical weather prediction (NWP) limits accuracy due to high computational cost and strict time-to-solution limits. We report that a data-driven deep learning Earth system emulator, FourCastNet, can predict global weather and generate medium-range forecasts five orders-of-magnitude faster than NWP while approaching state-of-the-art accuracy. FourCast-Net is optimized and scales efficiently on three supercomputing systems: Selene, Perlmutter, and JUWELS Booster up to 3,808 NVIDIA A100 GPUs, attaining 140.8 petaFLOPS in mixed precision (11.9\%of peak at that scale). The time-to-solution for training FourCastNet measured on JUWELS Booster on 3,072GPUs is 67.4minutes, resulting in an 80,000times faster time-to-solution relative to state-of-the-art NWP, in inference. FourCastNet produces accurate instantaneous weather predictions for a week in advance, enables enormous ensembles that better capture weather extremes, and supports higher global forecast resolutions.},
	urldate = {2022-08-22},
	publisher = {arXiv},
	author = {Kurth, Thorsten and Subramanian, Shashank and Harrington, Peter and Pathak, Jaideep and Mardani, Morteza and Hall, David and Miele, Andrea and Kashinath, Karthik and Anandkumar, Animashree},
	month = aug,
	year = {2022},
	note = {arXiv:2208.05419 [physics]},
	keywords = {Physics - Atmospheric and Oceanic Physics, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Performance},
	file = {arXiv.org Snapshot:/Users/tsmith/Zotero/storage/U78S3MRL/2208.html:text/html;Kurth_et_al_2022_FourCastNet.pdf:/Users/tsmith/Drive/zotero/Kurth_et_al_2022_FourCastNet.pdf:application/pdf},
}

@article{furner_sensitivity_2022,
	title = {A sensitivity analysis of a regression model of ocean temperature},
	volume = {1},
	issn = {2634-4602},
	url = {https://www.cambridge.org/core/journals/environmental-data-science/article/sensitivity-analysis-of-a-regression-model-of-ocean-temperature/089EA5B347F262CEE0B4BDFFBA4E6FF5},
	doi = {10.1017/eds.2022.10},
	abstract = {There has been much recent interest in developing data-driven models for weather and climate predictions. However, there are open questions regarding their generalizability and robustness, highlighting a need to better understand how they make their predictions. In particular, it is important to understand whether data-driven models learn the underlying physics of the system against which they are trained, or simply identify statistical patterns without any clear link to the underlying physics. In this paper, we describe a sensitivity analysis of a regression-based model of ocean temperature, trained against simulations from a 3D ocean model setup in a very simple configuration. We show that the regressor heavily bases its forecasts on, and is dependent on, variables known to be key to the physics such as currents and density. By contrast, the regressor does not make heavy use of inputs such as location, which have limited direct physical impacts. The model requires nonlinear interactions between inputs in order to show any meaningful skill—in line with the highly nonlinear dynamics of the ocean. Further analysis interprets the ways certain variables are used by the regression model. We see that information about the vertical profile of the water column reduces errors in regions of convective activity, and information about the currents reduces errors in regions dominated by advective processes. Our results demonstrate that even a simple regression model is capable of learning much of the physics of the system being modeled. We expect that a similar sensitivity analysis could be usefully applied to more complex ocean configurations.},
	language = {en},
	urldate = {2022-09-08},
	journal = {Environmental Data Science},
	author = {Furner, Rachel and Haynes, Peter and Munday, Dave and Paige, Brooks and Jones, Daniel C. and Shuckburgh, Emily},
	year = {2022},
	note = {Publisher: Cambridge University Press},
	keywords = {oceanography, Data science, interpretable ML, model sensitivity, regression model},
	pages = {e11},
	file = {Furner_et_al_2022_A_sensitivity_analysis_of_a_regression_model_of_ocean_temperature.pdf:/Users/tsmith/Drive/zotero/Furner_et_al_2022_A_sensitivity_analysis_of_a_regression_model_of_ocean_temperature.pdf:application/pdf},
}

@article{weyn_sub-seasonal_2021,
	title = {Sub-{Seasonal} {Forecasting} {With} a {Large} {Ensemble} of {Deep}-{Learning} {Weather} {Prediction} {Models}},
	volume = {13},
	issn = {1942-2466},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2021MS002502},
	doi = {10.1029/2021MS002502},
	abstract = {We present an ensemble prediction system using a Deep Learning Weather Prediction (DLWP) model that recursively predicts six key atmospheric variables with six-hour time resolution. This computationally efficient model uses convolutional neural networks (CNNs) on a cubed sphere grid to produce global forecasts. The trained model requires just three minutes on a single GPU to produce a 320-member set of six-week forecasts at 1.4° resolution. Ensemble spread is primarily produced by randomizing the CNN training process to create a set of 32 DLWP models with slightly different learned weights. Although our DLWP model does not forecast precipitation, it does forecast total column water vapor and gives a reasonable 4.5-day deterministic forecast of Hurricane Irma. In addition to simulating mid-latitude weather systems, it spontaneously generates tropical cyclones in a one-year free-running simulation. Averaged globally and over a two-year test set, the ensemble mean RMSE retains skill relative to climatology beyond two-weeks, with anomaly correlation coefficients remaining above 0.6 through six days. Our primary application is to subseasonal-to-seasonal (S2S) forecasting at lead times from two to six weeks. Current forecast systems have low skill in predicting one- or 2-week-average weather patterns at S2S time scales. The continuous ranked probability score (CRPS) and the ranked probability skill score (RPSS) show that the DLWP ensemble is only modestly inferior in performance to the European Center for Medium Range Weather Forecasts (ECMWF) S2S ensemble over land at lead times of 4 and 5–6 weeks. At shorter lead times, the ECMWF ensemble performs better than DLWP.},
	language = {en},
	number = {7},
	urldate = {2022-10-03},
	journal = {Journal of Advances in Modeling Earth Systems},
	author = {Weyn, Jonathan A. and Durran, Dale R. and Caruana, Rich and Cresswell-Clay, Nathaniel},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2021MS002502},
	keywords = {machine learning, Deep learning, NWP, S2S},
	pages = {e2021MS002502},
	annote = {e2021MS002502 2021MS002502},
	file = {Snapshot:/Users/tsmith/Zotero/storage/CEGLP337/2021MS002502.html:text/html;Weyn_et_al_2021_Sub-Seasonal_Forecasting_With_a_Large_Ensemble_of_Deep-Learning_Weather.pdf:/Users/tsmith/Drive/zotero/Weyn_et_al_2021_Sub-Seasonal_Forecasting_With_a_Large_Ensemble_of_Deep-Learning_Weather.pdf:application/pdf},
}

@article{weyn_improving_2020,
	title = {Improving {Data}-{Driven} {Global} {Weather} {Prediction} {Using} {Deep} {Convolutional} {Neural} {Networks} on a {Cubed} {Sphere}},
	volume = {12},
	issn = {1942-2466},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2020MS002109},
	doi = {10.1029/2020MS002109},
	abstract = {We present a significantly improved data-driven global weather forecasting framework using a deep convolutional neural network (CNN) to forecast several basic atmospheric variables on a global grid. New developments in this framework include an off-line volume-conservative mapping to a cubed-sphere grid, improvements to the CNN architecture and the minimization of the loss function over multiple steps in a prediction sequence. The cubed-sphere remapping minimizes the distortion on the cube faces on which convolution operations are performed and provides natural boundary conditions for padding in the CNN. Our improved model produces weather forecasts that are indefinitely stable and produce realistic weather patterns at lead times of several weeks and longer. For short- to medium-range forecasting, our model significantly outperforms persistence, climatology, and a coarse-resolution dynamical numerical weather prediction (NWP) model. Unsurprisingly, our forecasts are worse than those from a high-resolution state-of-the-art operational NWP system. Our data-driven model is able to learn to forecast complex surface temperature patterns from few input atmospheric state variables. On annual time scales, our model produces a realistic seasonal cycle driven solely by the prescribed variation in top-of-atmosphere solar forcing. Although it currently does not compete with operational weather forecasting models, our data-driven CNN executes much faster than those models, suggesting that machine learning could prove to be a valuable tool for large-ensemble forecasting.},
	language = {en},
	number = {9},
	urldate = {2022-10-03},
	journal = {Journal of Advances in Modeling Earth Systems},
	author = {Weyn, Jonathan A. and Durran, Dale R. and Caruana, Rich},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2020MS002109},
	pages = {e2020MS002109},
	annote = {e2020MS002109 10.1029/2020MS002109},
	file = {Snapshot:/Users/tsmith/Zotero/storage/X2BALKJA/2020MS002109.html:text/html;Weyn_et_al_2020_Improving_Data-Driven_Global_Weather_Prediction_Using_Deep_Convolutional_Neural.pdf:/Users/tsmith/Drive/zotero/Weyn_et_al_2020_Improving_Data-Driven_Global_Weather_Prediction_Using_Deep_Convolutional_Neural.pdf:application/pdf},
}

@article{scher_weather_2019,
	title = {Weather and climate forecasting with neural networks: using general circulation models ({GCMs}) with different complexity as a study ground},
	volume = {12},
	issn = {1991-959X},
	shorttitle = {Weather and climate forecasting with neural networks},
	url = {https://gmd.copernicus.org/articles/12/2797/2019/},
	doi = {10.5194/gmd-12-2797-2019},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} Recently, there has been growing interest in the possibility of using neural networks for both weather forecasting and the generation of climate datasets. We use a bottom–up approach for assessing whether it should, in principle, be possible to do this. We use the relatively simple general circulation models (GCMs) PUMA and PLASIM as a simplified reality on which we train deep neural networks, which we then use for predicting the model weather at lead times of a few days. We specifically assess how the complexity of the climate model affects the neural network's forecast skill and how dependent the skill is on the length of the provided training period. Additionally, we show that using the neural networks to reproduce the climate of general circulation models including a seasonal cycle remains challenging – in contrast to earlier promising results on a model without seasonal cycle.{\textless}/p{\textgreater}},
	language = {English},
	number = {7},
	urldate = {2022-10-03},
	journal = {Geoscientific Model Development},
	author = {Scher, Sebastian and Messori, Gabriele},
	month = jul,
	year = {2019},
	note = {Publisher: Copernicus GmbH},
	pages = {2797--2809},
	file = {Scher_Messori_2019_Weather_and_climate_forecasting_with_neural_networks.pdf:/Users/tsmith/Drive/zotero/Scher_Messori_2019_Weather_and_climate_forecasting_with_neural_networks.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/LQUNMMG8/gmd-12-2797-2019-discussion.html:text/html},
}

@article{weyn_can_2019,
	title = {Can {Machines} {Learn} to {Predict} {Weather}? {Using} {Deep} {Learning} to {Predict} {Gridded} 500-{hPa} {Geopotential} {Height} {From} {Historical} {Weather} {Data}},
	volume = {11},
	issn = {1942-2466},
	shorttitle = {Can {Machines} {Learn} to {Predict} {Weather}?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2019MS001705},
	doi = {10.1029/2019MS001705},
	abstract = {We develop elementary weather prediction models using deep convolutional neural networks (CNNs) trained on past weather data to forecast one or two fundamental meteorological fields on a Northern Hemisphere grid with no explicit knowledge about physical processes. At forecast lead times up to 3 days, CNNs trained to predict only 500-hPa geopotential height easily outperform persistence, climatology, and the dynamics-based barotropic vorticity model, but do not beat an operational full-physics weather prediction model. These CNNs are capable of forecasting significant changes in the intensity of weather systems, which is notable because this is beyond the capability of the fundamental dynamical equation that relies solely on 500-hPa data, the barotropic vorticity equation. Modest improvements to the CNN forecasts can be made by adding 700- to 300-hPa thickness to the input data. Our best performing CNN does a good job of capturing the climatology and annual variability of 500-hPa heights and is capable of forecasting realistic atmospheric states at lead times of 14 days. Although our simple models do not perform better than an operational weather model, machine learning warrants further exploration as a weather forecasting tool; in particular, the potential efficiency of CNNs might make them attractive for ensemble forecasting.},
	language = {en},
	number = {8},
	urldate = {2022-10-03},
	journal = {Journal of Advances in Modeling Earth Systems},
	author = {Weyn, Jonathan A. and Durran, Dale R. and Caruana, Rich},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2019MS001705},
	keywords = {machine learning, weather prediction, deep learning, neural network},
	pages = {2680--2693},
	file = {Snapshot:/Users/tsmith/Zotero/storage/FRCJ3UNE/2019MS001705.html:text/html;Weyn_et_al_2019_Can_Machines_Learn_to_Predict_Weather.pdf:/Users/tsmith/Drive/zotero/Weyn_et_al_2019_Can_Machines_Learn_to_Predict_Weather.pdf:application/pdf},
}

@inproceedings{shi_convolutional_2015,
	title = {Convolutional {LSTM} {Network}: {A} {Machine} {Learning} {Approach} for {Precipitation} {Nowcasting}},
	volume = {28},
	shorttitle = {Convolutional {LSTM} {Network}},
	url = {https://proceedings.neurips.cc/paper/2015/hash/07563a3fe3bbe7e3ba84431ad9d055af-Abstract.html},
	abstract = {The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting.},
	urldate = {2022-10-03},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {SHI, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-kin and WOO, Wang-chun},
	year = {2015},
	file = {SHI_et_al_2015_Convolutional_LSTM_Network.pdf:/Users/tsmith/Drive/zotero/SHI_et_al_2015_Convolutional_LSTM_Network.pdf:application/pdf},
}

@article{rasp_data-driven_2021,
	title = {Data-{Driven} {Medium}-{Range} {Weather} {Prediction} {With} a {Resnet} {Pretrained} on {Climate} {Simulations}: {A} {New} {Model} for {WeatherBench}},
	volume = {13},
	issn = {1942-2466},
	shorttitle = {Data-{Driven} {Medium}-{Range} {Weather} {Prediction} {With} a {Resnet} {Pretrained} on {Climate} {Simulations}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2020MS002405},
	doi = {10.1029/2020MS002405},
	abstract = {Numerical weather prediction has traditionally been based on the models that discretize the dynamical and physical equations of the atmosphere. Recently, however, the rise of deep learning has created increased interest in purely data-driven medium-range weather forecasting with first studies exploring the feasibility of such an approach. To accelerate progress in this area, the WeatherBench benchmark challenge was defined. Here, we train a deep residual convolutional neural network (Resnet) to predict geopotential, temperature and precipitation at 5.625° resolution up to 5 days ahead. To avoid overfitting and improve forecast skill, we pretrain the model using historical climate model output before fine-tuning on reanalysis data. The resulting forecasts outperform previous submissions to WeatherBench and are comparable in skill to a physical baseline at similar resolution. We also analyze how the neural network creates its predictions and find that, for the case studies analyzed, the model has learned physically reasonable correlations. Finally, we perform scaling experiments to estimate the potential skill of data-driven approaches at higher resolutions.},
	language = {en},
	number = {2},
	urldate = {2022-10-03},
	journal = {Journal of Advances in Modeling Earth Systems},
	author = {Rasp, Stephan and Thuerey, Nils},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2020MS002405},
	keywords = {machine learning, deep learning, numerical weather forecasting},
	pages = {e2020MS002405},
	annote = {e2020MS002405 2020MS002405},
	file = {Rasp_Thuerey_2021_Data-Driven_Medium-Range_Weather_Prediction_With_a_Resnet_Pretrained_on_Climate.pdf:/Users/tsmith/Drive/zotero/Rasp_Thuerey_2021_Data-Driven_Medium-Range_Weather_Prediction_With_a_Resnet_Pretrained_on_Climate.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/T3N9E3J5/2020MS002405.html:text/html},
}

@article{clare_combining_2021,
	title = {Combining distribution-based neural networks to predict weather forecast probabilities},
	volume = {147},
	issn = {1477-870X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qj.4180},
	doi = {10.1002/qj.4180},
	abstract = {The success of deep learning techniques over the last decades has opened up a new avenue of research for weather forecasting. Here, we take the novel approach of using a neural network to predict full probability density functions at each point in space and time rather than a single output value, thus producing a probabilistic weather forecast. This enables the calculation of both uncertainty and skill metrics for the neural network predictions, and overcomes the common difficulty of inferring uncertainty from these predictions. This approach is data-driven and the neural network is trained on the WeatherBench dataset (processed ERA5 data) to forecast geopotential and temperature 3 and 5 days ahead. Data exploration leads to the identification of the most important input variables. In order to increase computational efficiency, several neural networks are trained on small subsets of these variables. The outputs are then combined through a stacked neural network, the first time such a technique has been applied to weather data. Our approach is found to be more accurate than some coarse numerical weather prediction models and as accurate as more complex alternative neural networks, with the added benefit of providing key probabilistic information necessary for making informed weather forecasts.},
	language = {en},
	number = {741},
	urldate = {2022-10-03},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Clare, Mariana C.A. and Jamil, Omar and Morcrette, Cyril J.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/qj.4180},
	keywords = {deep learning, data exploration, ensemble dropout, probabilistic weather forecasting, probability density functions, ResNet, stacked neural network},
	pages = {4337--4357},
	file = {Clare_et_al_2021_Combining_distribution-based_neural_networks_to_predict_weather_forecast.pdf:/Users/tsmith/Drive/zotero/Clare_et_al_2021_Combining_distribution-based_neural_networks_to_predict_weather_forecast.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/L7MLLTLD/qj.html:text/html},
}

@article{faranda_enhancing_2021,
	title = {Enhancing geophysical flow machine learning performance via scale separation},
	volume = {28},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/28/423/2021/},
	doi = {10.5194/npg-28-423-2021},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} Recent advances in statistical and machine learning have opened the possibility of forecasting the behaviour of chaotic systems using recurrent neural networks. In this article we investigate the applicability of such a framework to geophysical flows, known to involve multiple scales in length, time and energy and to feature intermittency. We show that both multiscale dynamics and intermittency introduce severe limitations to the applicability of recurrent neural networks, both for short-term forecasts as well as for the reconstruction of the underlying attractor. We suggest that possible strategies to overcome such limitations should be based on separating the smooth large-scale dynamics from the intermittent/small-scale features. We test these ideas on global sea-level pressure data for the past 40 years, a proxy of the atmospheric circulation dynamics. Better short- and long-term forecasts of sea-level pressure data can be obtained with an optimal choice of spatial coarse graining and time filtering.{\textless}/p{\textgreater}},
	language = {English},
	number = {3},
	urldate = {2022-10-03},
	journal = {Nonlinear Processes in Geophysics},
	author = {Faranda, Davide and Vrac, Mathieu and Yiou, Pascal and Pons, Flavio Maria Emanuele and Hamid, Adnane and Carella, Giulia and Ngoungue Langue, Cedric and Thao, Soulivanh and Gautard, Valerie},
	month = sep,
	year = {2021},
	note = {Publisher: Copernicus GmbH},
	pages = {423--443},
	file = {Faranda_et_al_2021_Enhancing_geophysical_flow_machine_learning_performance_via_scale_separation.pdf:/Users/tsmith/Drive/zotero/Faranda_et_al_2021_Enhancing_geophysical_flow_machine_learning_performance_via_scale_separation.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/ZZ3HHTKT/2021.html:text/html},
}

@article{maulik_efficient_2022,
	title = {Efficient high-dimensional variational data assimilation with machine-learned reduced-order models},
	volume = {15},
	issn = {1991-9603},
	url = {https://gmd.copernicus.org/articles/15/3433/2022/},
	doi = {10.5194/gmd-15-3433-2022},
	abstract = {Data assimilation (DA) in geophysical sciences remains the cornerstone of robust forecasts from numerical models. Indeed, DA plays a crucial role in the quality of numerical weather prediction and is a crucial building block that has allowed dramatic improvements in weather forecasting over the past few decades. DA is commonly framed in a variational setting, where one solves an optimization problem within a Bayesian formulation using raw model forecasts as a prior and observations as likelihood. This leads to a DA objective function that needs to be minimized, where the decision variables are the initial conditions speciﬁed to the model. In traditional DA, the forward model is numerically and computationally expensive. Here we replace the forward model with a low-dimensional, data-driven, and differentiable emulator. Consequently, gradients of our DA objective function with respect to the decision variables are obtained rapidly via automatic differentiation. We demonstrate our approach by performing an emulator-assisted DA forecast of geopotential height. Our results indicate that emulatorassisted DA is faster than traditional equation-based DA forecasts by 4 orders of magnitude, allowing computations to be performed on a workstation rather than a dedicated highperformance computer. In addition, we describe accuracy beneﬁts of emulator-assisted DA when compared to simply using the emulator for forecasting (i.e., without DA). Our overall formulation is denoted AIEADA (Artiﬁcial Intelligence Emulator-Assisted Data Assimilation).},
	language = {en},
	number = {8},
	urldate = {2022-10-03},
	journal = {Geoscientific Model Development},
	author = {Maulik, Romit and Rao, Vishwas and Wang, Jiali and Mengaldo, Gianmarco and Constantinescu, Emil and Lusch, Bethany and Balaprakash, Prasanna and Foster, Ian and Kotamarthi, Rao},
	month = may,
	year = {2022},
	pages = {3433--3445},
	file = {Maulik_et_al_2022_Efficient_high-dimensional_variational_data_assimilation_with_machine-learned.pdf:/Users/tsmith/Drive/zotero/Maulik_et_al_2022_Efficient_high-dimensional_variational_data_assimilation_with_machine-learned.pdf:application/pdf},
}

@article{nonnenmacher_deep_2021,
	title = {Deep {Emulators} for {Differentiation}, {Forecasting}, and {Parametrization} in {Earth} {Science} {Simulators}},
	volume = {13},
	issn = {1942-2466},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2021MS002554},
	doi = {10.1029/2021MS002554},
	abstract = {To understand and predict large, complex, and chaotic systems, Earth scientists build simulators from physical laws. Simulators generalize better to new scenarios, require fewer tunable parameters, and are more interpretable than nonphysical deep learning, but procedures for obtaining their derivatives with respect to their inputs are often unavailable. These missing derivatives limit the application of many important tools for forecasting, model tuning, sensitivity analysis, or subgrid-scale parametrization. Here, we propose to overcome this limitation with deep emulator networks that learn to calculate the missing derivatives. By training directly on simulation data without analyzing source code or equations, this approach supports simulators in any programming language on any hardware without specialized routines for each case. To demonstrate the effectiveness of our approach, we train emulators on complete or partial system states of the chaotic Lorenz-96 simulator and evaluate the accuracy of their dynamics and derivatives as a function of integration time and training data set size. We further demonstrate that emulator-derived derivatives enable accurate 4D-Var data assimilation and closed-loop training of parametrizations. These results provide a basis for further combining the parsimony and generality of physical models with the power and flexibility of machine learning.},
	language = {en},
	number = {7},
	urldate = {2022-10-03},
	journal = {Journal of Advances in Modeling Earth Systems},
	author = {Nonnenmacher, Marcel and Greenberg, David S.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2021MS002554},
	keywords = {machine learning, data assimilation, Lorenz-96, deep learning, model Jacobians, parametrization tuning},
	pages = {e2021MS002554},
	annote = {e2021MS002554 2021MS002554},
	file = {Nonnenmacher_Greenberg_2021_Deep_Emulators_for_Differentiation,_Forecasting,_and_Parametrization_in_Earth.pdf:/Users/tsmith/Drive/zotero/Nonnenmacher_Greenberg_2021_Deep_Emulators_for_Differentiation,_Forecasting,_and_Parametrization_in_Earth.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/QDG5DWSI/2021MS002554.html:text/html},
}

@article{schultz_can_2021,
	title = {Can deep learning beat numerical weather prediction?},
	volume = {379},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0097},
	doi = {10.1098/rsta.2020.0097},
	abstract = {The recent hype about artificial intelligence has sparked renewed interest in applying the successful deep learning (DL) methods for image recognition, speech recognition, robotics, strategic games and other application areas to the field of meteorology. There is some evidence that better weather forecasts can be produced by introducing big data mining and neural networks into the weather prediction workflow. Here, we discuss the question of whether it is possible to completely replace the current numerical weather models and data assimilation systems with DL approaches. This discussion entails a review of state-of-the-art machine learning concepts and their applicability to weather data with its pertinent statistical properties. We think that it is not inconceivable that numerical weather models may one day become obsolete, but a number of fundamental breakthroughs are needed before this goal comes into reach.

This article is part of the theme issue ‘Machine learning for weather and climate modelling’.},
	number = {2194},
	urldate = {2022-10-07},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Schultz, M. G. and Betancourt, C. and Gong, B. and Kleinert, F. and Langguth, M. and Leufen, L. H. and Mozaffari, A. and Stadtler, S.},
	month = apr,
	year = {2021},
	note = {Publisher: Royal Society},
	keywords = {machine learning, deep learning, numerical weather prediction, spatiotemporal pattern recognition, weather AI},
	pages = {20200097},
	file = {Schultz_et_al_2021_Can_deep_learning_beat_numerical_weather_prediction.pdf:/Users/tsmith/Drive/zotero/Schultz_et_al_2021_Can_deep_learning_beat_numerical_weather_prediction.pdf:application/pdf},
}


@article{scher_toward_2018,
	title = {Toward {Data}-{Driven} {Weather} and {Climate} {Forecasting}: {Approximating} a {Simple} {General} {Circulation} {Model} {With} {Deep} {Learning}},
	volume = {45},
	issn = {1944-8007},
	shorttitle = {Toward {Data}-{Driven} {Weather} and {Climate} {Forecasting}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2018GL080704},
	doi = {10.1029/2018GL080704},
	abstract = {It is shown that it is possible to emulate the dynamics of a simple general circulation model with a deep neural network. After being trained on the model, the network can predict the complete model state several time steps ahead—which conceptually is making weather forecasts in the model world. Additionally, after being initialized with an arbitrary model state, the network can through repeatedly feeding back its predictions into its inputs create a climate run, which has similar climate statistics to the climate of the general circulation model. This network climate run shows no long-term drift, even though no conservation properties were explicitly designed into the network.},
	language = {en},
	number = {22},
	urldate = {2022-10-11},
	journal = {Geophysical Research Letters},
	author = {Scher, S.},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2018GL080704},
	keywords = {climate models, deep learning, machine learning, neural networks, weather prediction},
	pages = {12,616--12,622},
	file = {Scher_2018_Toward_Data-Driven_Weather_and_Climate_Forecasting.pdf:/Users/tsmith/Drive/zotero/Scher_2018_Toward_Data-Driven_Weather_and_Climate_Forecasting.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/DDXA5NIS/2018GL080704.html:text/html},
}


@article{hersbach_era5_2020,
	title = {The {ERA5} global reanalysis},
	volume = {146},
	issn = {1477-870X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qj.3803},
	doi = {10.1002/qj.3803},
	abstract = {Within the Copernicus Climate Change Service (C3S), ECMWF is producing the ERA5 reanalysis which, once completed, will embody a detailed record of the global atmosphere, land surface and ocean waves from 1950 onwards. This new reanalysis replaces the ERA-Interim reanalysis (spanning 1979 onwards) which was started in 2006. ERA5 is based on the Integrated Forecasting System (IFS) Cy41r2 which was operational in 2016. ERA5 thus benefits from a decade of developments in model physics, core dynamics and data assimilation. In addition to a significantly enhanced horizontal resolution of 31 km, compared to 80 km for ERA-Interim, ERA5 has hourly output throughout, and an uncertainty estimate from an ensemble (3-hourly at half the horizontal resolution). This paper describes the general set-up of ERA5, as well as a basic evaluation of characteristics and performance, with a focus on the dataset from 1979 onwards which is currently publicly available. Re-forecasts from ERA5 analyses show a gain of up to one day in skill with respect to ERA-Interim. Comparison with radiosonde and PILOT data prior to assimilation shows an improved fit for temperature, wind and humidity in the troposphere, but not the stratosphere. A comparison with independent buoy data shows a much improved fit for ocean wave height. The uncertainty estimate reflects the evolution of the observing systems used in ERA5. The enhanced temporal and spatial resolution allows for a detailed evolution of weather systems. For precipitation, global-mean correlation with monthly-mean GPCP data is increased from 67\% to 77\%. In general, low-frequency variability is found to be well represented and from 10 hPa downwards general patterns of anomalies in temperature match those from the ERA-Interim, MERRA-2 and JRA-55 reanalyses.},
	language = {en},
	number = {730},
	urldate = {2022-10-11},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Hersbach, Hans and Bell, Bill and Berrisford, Paul and Hirahara, Shoji and Horányi, András and Muñoz-Sabater, Joaquín and Nicolas, Julien and Peubey, Carole and Radu, Raluca and Schepers, Dinand and Simmons, Adrian and Soci, Cornel and Abdalla, Saleh and Abellan, Xavier and Balsamo, Gianpaolo and Bechtold, Peter and Biavati, Gionata and Bidlot, Jean and Bonavita, Massimo and De Chiara, Giovanna and Dahlgren, Per and Dee, Dick and Diamantakis, Michail and Dragani, Rossana and Flemming, Johannes and Forbes, Richard and Fuentes, Manuel and Geer, Alan and Haimberger, Leo and Healy, Sean and Hogan, Robin J. and Hólm, Elías and Janisková, Marta and Keeley, Sarah and Laloyaux, Patrick and Lopez, Philippe and Lupu, Cristina and Radnoti, Gabor and de Rosnay, Patricia and Rozum, Iryna and Vamborg, Freja and Villaume, Sebastien and Thépaut, Jean-Noël},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/qj.3803},
	keywords = {climate reanalysis, Copernicus Climate Change Service, data assimilation, ERA5, historical observations},
	pages = {1999--2049},
	file = {Hersbach_et_al_2020_The_ERA5_global_reanalysis.pdf:/Users/tsmith/Drive/zotero/Hersbach_et_al_2020_The_ERA5_global_reanalysis.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/YRUI7UXB/qj.html:text/html},
}


@techreport{penny_coupled_2017,
	title = {Coupled {Data} {Assimilation} for {Integrated} {Earth} {System} {Analysis} and {Prediction}: {Goals}, {Challenges} and {Recommendations}},
	institution = {Geneva: World Meteorological Organization.},
	author = {Penny, Stephen G. and Akella, Santha and Alves, Oscar and Craig, Bishop and Buehner, Mark and Chevallier, Matthieu and Counillon, Francois and Draper, Clara and Frolov, Sergey and Fujii, Yosuke and Karspeck, Alicia and Kumar, Arun and Laloyaux, Patrick and Mahfouf, Jean-Francois and Martin, Matthew and Peña, Malaquias and de Rosnay, Patricia and Subramanian, Aneesh and Tardif, Robert and Wang, Yiguo and Wu, Xingren},
	year = {2017},
	file = {Penny_et_al_2017_Coupled_Data_Assimilation_for_Integrated_Earth_System_Analysis_and_Prediction.pdf:/Users/tsmith/Drive/zotero/Penny_et_al_2017_Coupled_Data_Assimilation_for_Integrated_Earth_System_Analysis_and_Prediction.pdf:application/pdf},
}


@article{hewitt_impact_2016,
	title = {The impact of resolving the {Rossby} radius at mid-latitudes in the ocean: results from a high-resolution version of the {Met} {Office} {GC2} coupled model},
	volume = {9},
	issn = {1991-959X},
	shorttitle = {The impact of resolving the {Rossby} radius at mid-latitudes in the ocean},
	url = {https://gmd.copernicus.org/articles/9/3655/2016/},
	doi = {10.5194/gmd-9-3655-2016},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} There is mounting evidence that resolving mesoscale eddies and western boundary currents as well as topographically controlled flows can play an important role in air–sea interaction associated with vertical and lateral transports of heat and salt. Here we describe the development of the Met Office Global Coupled Model version 2 (GC2) with increased resolution relative to the standard model: the ocean resolution is increased from 1/4 to 1/12° (28 to 9 km at the Equator), the atmosphere resolution increased from 60 km (N216) to 25 km (N512) and the coupling period reduced from 3 hourly to hourly. The technical developments that were required to build a version of the model at higher resolution are described as well as results from a 20-year simulation. The results demonstrate the key role played by the enhanced resolution of the ocean model: reduced sea surface temperature (SST) biases, improved ocean heat transports, deeper and stronger overturning circulation and a stronger Antarctic Circumpolar Current. Our results suggest that the improvements seen here require high resolution in both atmosphere and ocean components as well as high-frequency coupling. These results add to the body of evidence suggesting that ocean resolution is an important consideration when developing coupled models for weather and climate applications.{\textless}/p{\textgreater}},
	language = {English},
	number = {10},
	urldate = {2022-02-08},
	journal = {Geoscientific Model Development},
	author = {Hewitt, Helene T. and Roberts, Malcolm J. and Hyder, Pat and Graham, Tim and Rae, Jamie and Belcher, Stephen E. and Bourdallé-Badie, Romain and Copsey, Dan and Coward, Andrew and Guiavarch, Catherine and Harris, Chris and Hill, Richard and Hirschi, Joël J.-M. and Madec, Gurvan and Mizielinski, Matthew S. and Neininger, Erica and New, Adrian L. and Rioual, Jean-Christophe and Sinha, Bablu and Storkey, David and Shelly, Ann and Thorpe, Livia and Wood, Richard A.},
	month = oct,
	year = {2016},
	note = {Publisher: Copernicus GmbH},
	pages = {3655--3670},
	file = {Hewitt_et_al_2016_The_impact_of_resolving_the_Rossby_radius_at_mid-latitudes_in_the_ocean.pdf:/Users/tsmith/Drive/zotero/Hewitt_et_al_2016_The_impact_of_resolving_the_Rossby_radius_at_mid-latitudes_in_the_ocean.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/679MIVS2/2016.html:text/html},
}

@book{evensen_data_2022,
	address = {Cham},
	series = {Springer {Textbooks} in {Earth} {Sciences}, {Geography} and {Environment}},
	title = {Data {Assimilation} {Fundamentals}: {A} {Unified} {Formulation} of the {State} and {Parameter} {Estimation} {Problem}},
	isbn = {978-3-030-96708-6 978-3-030-96709-3},
	shorttitle = {Data {Assimilation} {Fundamentals}},
	url = {https://link.springer.com/10.1007/978-3-030-96709-3},
	language = {en},
	urldate = {2022-06-08},
	publisher = {Springer International Publishing},
	author = {Evensen, Geir and Vossepoel, Femke C. and van Leeuwen, Peter Jan},
	year = {2022},
	doi = {10.1007/978-3-030-96709-3},
	file = {Evensen_et_al_2022_Data_Assimilation_Fundamentals.pdf:/Users/tsmith/Drive/zotero/Evensen_et_al_2022_Data_Assimilation_Fundamentals.pdf:application/pdf},
}


@article{bui-thanh_model_2008,
	title = {Model {Reduction} for {Large}-{Scale} {Systems} with {High}-{Dimensional} {Parametric} {Input} {Space}},
	volume = {30},
	issn = {1064-8275},
	url = {https://epubs.siam.org/doi/10.1137/070694855},
	doi = {10.1137/070694855},
	abstract = {A model-constrained adaptive sampling methodology is proposed for the reduction of large-scale systems with high-dimensional parametric input spaces. Our model reduction method uses a reduced basis approach, which requires the computation of high-fidelity solutions at a number of sample points throughout the parametric input space. A key challenge that must be addressed in the optimization, control, and probabilistic settings is the need for the reduced models to capture variation over this parametric input space, which, for many applications, will be of high dimension. We pose the task of determining appropriate sample points as a PDE-constrained optimization problem, which is implemented using an efficient adaptive algorithm that scales well to systems with a large number of parameters. The methodology is demonstrated using examples with parametric input spaces of dimension 11 and 21, which describe thermal analysis and design of a heat conduction fin, and compared with statistically based sampling methods. For these examples, the model-constrained adaptive sampling leads to reduced models that, for a given basis size, have error several orders of magnitude smaller than that obtained using the other methods.},
	number = {6},
	urldate = {2022-10-11},
	journal = {SIAM Journal on Scientific Computing},
	author = {Bui-Thanh, T. and Willcox, K. and Ghattas, O.},
	month = jan,
	year = {2008},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {37M99, 37N40, 65K10, heat conduction, model reduction, optimization, sampling},
	pages = {3270--3288},
	file = {Bui-Thanh_et_al_2008_Model_Reduction_for_Large-Scale_Systems_with_High-Dimensional_Parametric_Input.pdf:/Users/tsmith/Drive/zotero/Bui-Thanh_et_al_2008_Model_Reduction_for_Large-Scale_Systems_with_High-Dimensional_Parametric_Input.pdf:application/pdf},
}

@article{najm_uncertainty_2009,
	title = {Uncertainty {Quantification} and {Polynomial} {Chaos} {Techniques} in {Computational} {Fluid} {Dynamics}},
	volume = {41},
	url = {https://doi.org/10.1146/annurev.fluid.010908.165248},
	doi = {10.1146/annurev.fluid.010908.165248},
	abstract = {The quantification of uncertainty in computational fluid dynamics (CFD) predictions is both a significant challenge and an important goal. Probabilistic uncertainty quantification (UQ) methods have been used to propagate uncertainty from model inputs to outputs when input uncertainties are large and have been characterized probabilistically. Polynomial chaos (PC) methods have found increased use in probabilistic UQ over the past decade. This review describes the use of PC expansions for the representation of random variables/fields and discusses their utility for the propagation of uncertainty in computational models, focusing on CFD models. Many CFD applications are considered, including flow in porous media, incompressible and compressible flows, and thermofluid and reacting flows. The review examines each application area, focusing on the demonstrated use of PC UQ and the associated challenges. Cross-cutting challenges with time unsteadiness and long time horizons are also discussed.},
	number = {1},
	urldate = {2022-10-11},
	journal = {Annual Review of Fluid Mechanics},
	author = {Najm, Habib N.},
	year = {2009},
	note = {\_eprint: https://doi.org/10.1146/annurev.fluid.010908.165248},
	keywords = {CFD, PC, polynomial chaos, UQ},
	pages = {35--52},
}


@article{huan_simulation-based_2013,
	title = {Simulation-based optimal {Bayesian} experimental design for nonlinear systems},
	volume = {232},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999112004597},
	doi = {10.1016/j.jcp.2012.08.013},
	abstract = {The optimal selection of experimental conditions is essential to maximizing the value of data for inference and prediction, particularly in situations where experiments are time-consuming and expensive to conduct. We propose a general mathematical framework and an algorithmic approach for optimal experimental design with nonlinear simulation-based models; in particular, we focus on finding sets of experiments that provide the most information about targeted sets of parameters. Our framework employs a Bayesian statistical setting, which provides a foundation for inference from noisy, indirect, and incomplete data, and a natural mechanism for incorporating heterogeneous sources of information. An objective function is constructed from information theoretic measures, reflecting expected information gain from proposed combinations of experiments. Polynomial chaos approximations and a two-stage Monte Carlo sampling method are used to evaluate the expected information gain. Stochastic approximation algorithms are then used to make optimization feasible in computationally intensive and high-dimensional settings. These algorithms are demonstrated on model problems and on nonlinear parameter inference problems arising in detailed combustion kinetics.},
	language = {en},
	number = {1},
	urldate = {2022-10-11},
	journal = {Journal of Computational Physics},
	author = {Huan, Xun and Marzouk, Youssef M.},
	month = jan,
	year = {2013},
	keywords = {Bayesian inference, Chemical kinetics, Nonlinear experimental design, Optimal experimental design, Shannon information, Stochastic approximation, Uncertainty quantification},
	pages = {288--317},
	file = {Huan_Marzouk_2013_Simulation-based_optimal_Bayesian_experimental_design_for_nonlinear_systems.pdf:/Users/tsmith/Drive/zotero/Huan_Marzouk_2013_Simulation-based_optimal_Bayesian_experimental_design_for_nonlinear_systems.pdf:application/pdf;ScienceDirect Snapshot:/Users/tsmith/Zotero/storage/5EWCJ8BV/S0021999112004597.html:text/html},
}


@article{hasselmann_pips_1988,
	title = {{PIPs} and {POPs}: {The} reduction of complex dynamical systems using principal interaction and oscillation patterns},
	volume = {93},
	issn = {2156-2202},
	shorttitle = {{PIPs} and {POPs}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/JD093iD09p11015},
	doi = {10.1029/JD093iD09p11015},
	abstract = {A general method is described for constructing simple dynamical models to approximate complex dynamical systems with many degrees of freedom. The technique can be applied to interpret sets of observed time series or numerical simulations with high-resolution models, or to relate observation and simulations. The method is based on a projection of the complete system on to a smaller number of “principal interaction patterns” (PIPs). The coefficients of the PIP expansion are assumed to be governed by a dynamic model containing a small number of adjustable parameters. The optimization of the dynamical model, which in the general case can be both nonlinear and time-dependent, is carried out simultaneously with the construction of the optimal set of interaction patterns. In the linear case the PIPs reduce to the eigenoscilations of a first-order linear vector process with stochastic forcing (principal oscillation patterns, or POPs). POPs are linearly related to the “principal prediction patterns” used in linear forecasting applications. The POP analysis can also be applied as a diagnostic tool to compress the extensive information contained in the high-dimensional cross-spectral covariance matrix representing the complete second-moment structure of the system.},
	language = {en},
	number = {D9},
	urldate = {2022-10-11},
	journal = {Journal of Geophysical Research: Atmospheres},
	author = {Hasselmann, K.},
	year = {1988},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/JD093iD09p11015},
	pages = {11015--11021},
	file = {Hasselmann_1988_PIPs_and_POPs.pdf:/Users/tsmith/Drive/zotero/Hasselmann_1988_PIPs_and_POPs.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/LPT6T3AZ/JD093iD09p11015.html:text/html},
}


@article{cressie_statistics_1993,
  title={Statistics for spatial data},
  author={Cressie, N},
  year={1993},
  publisher={Wiley Location New York, NY}
}
@article{penland_random_1989,
	title = {Random {Forcing} and {Forecasting} {Using} {Principal} {Oscillation} {Pattern} {Analysis}},
	volume = {117},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/117/10/1520-0493_1989_117_2165_rfafup_2_0_co_2.xml},
	doi = {10.1175/1520-0493(1989)117<2165:RFAFUP>2.0.CO;2},
	abstract = {Abstract The effects of random forcing and deterministic feedback are combined in a measured multivariate time series. It is shown here how the characteristics of the driving noise can be found after the deterministic effects have been identified by the principal oscillation pattern (POP) analysis. In addition, the POP analysis is extended to enable the prediction of the most probable meteorological pattern at some future time when the present pattern is known, and the conditional probability of finding the process at any location within a range of values given the value of the process at another location at an earlier time. Estimates of how well these predictions can be trusted are also given. The basic assumption of POP analysis is that the system can be optimally modeled by a linear Markov process.},
	language = {EN},
	number = {10},
	urldate = {2022-10-11},
	journal = {Monthly Weather Review},
	author = {Penland, Cecile},
	month = oct,
	year = {1989},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {2165--2185},
	file = {Penland_1989_Random_Forcing_and_Forecasting_Using_Principal_Oscillation_Pattern_Analysis.pdf:/Users/tsmith/Drive/zotero/Penland_1989_Random_Forcing_and_Forecasting_Using_Principal_Oscillation_Pattern_Analysis.pdf:application/pdf;Snapshot:/Users/tsmith/Zotero/storage/VCQU392N/1520-0493_1989_117_2165_rfafup_2_0_co_2.html:text/html},
}
